{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to assess uncertainty in regression coefficients?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load packages we will use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# math \n",
    "import numpy as np\n",
    "\n",
    "# dataframes\n",
    "import pandas as pd\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# linear regression two ways\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression coefficients are random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/udell/opt/anaconda3/lib/python3.9/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.09473637,  0.15347144])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD4CAYAAADvsV2wAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAASy0lEQVR4nO3df6hcZX7H8c/n2iyBGJGaa6JGvQqhblKqlSFVxOJ2dYlBmlVWSRZaaQvBVrHF/lGLsNs/CwX/yCrrRiqusGgDravgNVGXQrKgrhOJkjRrGy9ZvBtNJrGY3GwvJjvf/nFnwuQ6M3duzpk5v94vuGRmzpN5HoY73/uc73nO93FECABQfmNZDwAAMBoEfACoCAI+AFQEAR8AKoKADwAV8TtZD6CfFStWxMTERNbDAIDC2Lt37/GIGO92LNcBf2JiQvV6PethAEBh2P5Vr2OkdACgIgj4AFARBHwAqAgCPgBUBAEfACoilYBv+znbx2zv73H8Dttf2N7X+vleGv0iP5rN0FRjRm9/fFxTjRk1mxTlA/ImrWWZz0t6StILfdrsiYh7UuoPOdJshnYe+EyP7din2TNNLV0ypicfuEkb1q3S2JizHh6AllRm+BGxW9LnabwXiufwidPngr0kzZ5p6rEd+3T4xOmMRwag0yhz+Lfa/sD267bX9Wpke6vtuu16o9EY4fBwoY6enD0X7NtmzzR17NRsRiMC0M2oAv77kq6NiBsl/UDST3s1jIjtEVGLiNr4eNe7g5EzKy9ZqqVLzv9VWrpkTJcvX5rRiAB0M5KAHxEnI2Km9XhS0hLbK0bRN4Zv4rJlevKBm84F/XYOf+KyZRmPDECnkdTSsb1K0tGICNvrNfeH5sQo+sbwjY1ZG9at0g2P3q5jp2Z1+fKlmrhsGRdsgZxJJeDbflHSHZJW2J6W9H1JSyQpIp6R9B1Jf237rKT/k7Q52Ey3VMbGrOvHL9b14xdnPRQAPaQS8CNiywLHn9Lcsk0AQEa40xYAKoKADwAVQcAHgIog4ANARRDwAaAiCPgAUBG53sQcAJrN0OETp3X05KxWXsJNfUkQ8AHkFqW300VKB0BuUXo7XQR8ALlF6e10kdIBCmpYue085czbpbc7gz6lty8cAR8ooGHltvOWM2+X3p4/HkpvXxjnuWhlrVaLer2e9TCA3JlqzGjjtj1fmflOPnp7ooqlw3rfJNpnHJTeHoztvRFR63aMGT5QQP1y20kC82Led1SpH0pvp4eADxTQsHLbg75v3lI/GAyrdIACGta2koO+L8sli4kZPlBAw9pWctD3HVZKCcNFwAcKali57UHel+WSxURKB8CiDSulhOFihl8hebqhBsU2rJQShouAXxGsqkDaWC5ZPKmkdGw/Z/uY7f09jtv2NtuHbH9o++Y0+sXgWFUBIK0c/vOSNvQ5frekNa2frZJ+mFK/GBBFqACkEvAjYrekz/s02STphZjzjqRLbV+RRt8YTHtVRSdWVQDVMqpVOldJ+qTj+XTrta+wvdV23Xa90WiMZHBVwKoKAKO6aNvtqmDXqm0RsV3SdmmueNowB1UlrKoAMKqAPy3p6o7nqyUdGVHfaGFVBVBto0rpvCrpz1urdW6R9EVEfDqivgEASmmGb/tFSXdIWmF7WtL3JS2RpIh4RtKkpI2SDkn6jaS/SKNfAMDgUgn4EbFlgeMh6eE0+gIAXBjutMV5KL8Aid+DsiLg4xzKL0Di96DMqJaJcyi/AInfgzIj4OMcyi9A4vegzEjp4JxBNrUgt1t+bG5SXszwcc5C5Rfaud2N2/Zoy7PvauO2Pdp54DM1m9wQXSaU4Sgvz62YzKdarRb1ej3rYVRKewbfrfzCVGNGG7ft+crMb/LR27l7t2T6/R4g32zvjYhat2OkdHCefuUX2Li6OijDUU6kdDAwSiwDxUbAx8DI7QLFRkoHA6PEMlBsBHwsCrldoLhI6QBARRDwAaAiCPgAUBEEfACoCAI+AFQEAR8AKoKADwAVQcAHgIog4ANARRDwAaAiUgn4tjfY/sj2IduPdzl+h+0vbO9r/XwvjX4BAINLXEvH9kWSnpZ0l6RpSe/ZfjUi/mte0z0RcU/S/gAAFyaNGf56SYciYioivpT0kqRNKbwvACBFaQT8qyR90vF8uvXafLfa/sD267bX9Xoz21tt123XG41GCsMDAEjpBPxuxdDnb5T7vqRrI+JGST+Q9NNebxYR2yOiFhG18fHxFIYHAJDSCfjTkq7ueL5a0pHOBhFxMiJmWo8nJS2xvSKFvgFgKJrN0FRjRm9/fFxTjRk1m/PnscWTxgYo70laY/s6Sb+WtFnSdzsb2F4l6WhEhO31mvtDcyKFvgEgdc1maOeBz/TYjn2aPdM8t53nhnWrCr3DW+IZfkSclfSIpF2SDkraEREHbD9k+6FWs+9I2m/7A0nbJG2OiOL/uQRQSodPnD4X7CVp9kxTj+3Yp8MnTmc8smRS2eKwlaaZnPfaMx2Pn5L0VBp9AWXRbIYOnzitoydntfIS9gfOk6MnZ88F+7bZM00dOzVb6O092dMWyEBZUwZlsfKSpVq6ZOy8oL90yZguX740w1ElR2kFIANlTRmUxcRly/TkAzdp6ZK5ENn+gzxx2bKMR5YMM3wgA2VNGZTF2Ji1Yd0q3fDo7Tp2alaXLy9Hyo2AD2SgrCmDMhkbs64fv7hUf4BJ6QAZKGvKAPnGDB/IQFlTBsg3Aj6QkTKmDJBvpHQAoCKY4QMlwY1cWAgBHygBbuTCIEjpACXAjVwYBAEfKIF+N3IBbQR8oATaN3J14kYuzEfAB0qAG7kwCC7aAiXAjVwYBAEfKAlu5MJCSOkAQEUQ8AGgIgj4AFARBHwAqAgCPgBURCoB3/YG2x/ZPmT78S7HbXtb6/iHtm9Oo18AwOASB3zbF0l6WtLdktZK2mJ77bxmd0ta0/rZKumHSfsFACxOGjP89ZIORcRURHwp6SVJm+a12STphZjzjqRLbV+RQt8AgAGlEfCvkvRJx/Pp1muLbSNJsr3Vdt12vdFopDA8AICUTsDvdu92XECbuRcjtkdELSJq4+PjiQcHAJiTRmmFaUlXdzxfLenIBbTBELALEoC2NAL+e5LW2L5O0q8lbZb03XltXpX0iO2XJP2RpC8i4tMU+kYf7IIEoFPilE5EnJX0iKRdkg5K2hERB2w/ZPuhVrNJSVOSDkl6VtLfJO0XC2MXJACdUqmWGRGTmgvqna890/E4JD2cRl8YXL9dkKioiCyRaswG5ZFLrL0LUmfQZxckZI1UY3YorVBi7IKEPCLVmB1m+CXGLkjFV8bUB6nG7BDwS45dkIqrrKkPUo3ZIaUD5FRZUx+kGrPDDB/IqbKmPkg1ZoeAD+RUmVMfpBqzQUoHyClSH0gbM3wgp0h9IG0EfCDHSH0gTQR8YMjysJY+D2NA9gj4wBDlYS19HsaAfOCiLTBEeVhLn4cxIB9KF/CbzdBUY0Zvf3xcU40ZNZtdN9YCRqLfWvoqjaEXvq+jVaqUDqeuyJs8rKXPwxi64fs6eqWa4XPqirzJw1r6PIyhG76vo1eqGX5Zb0VHceVhLX0extAN39fRK1XAz+upK6otD2vp8zCG+fi+jl6pUjp5PXUF8FV8X0fPc9vN5lOtVot6vb6o/9O+wSRPp64AuuP7mj7beyOi1u1YqVI6Uj5PXQF0x/d1tBIFfNu/K+nfJE1IOizpgYj43y7tDks6Jem3ks72+usDABiepDn8xyX9LCLWSPpZ63kv34iImwj2AJCNpAF/k6Qftx7/WNK3E74fAGBIkgb8lRHxqSS1/r28R7uQ9Ibtvba39ntD21tt123XG41GwuEBANoWzOHbfkvSqi6HnlhEP7dFxBHbl0t60/YvI2J3t4YRsV3Sdmlulc4i+gAA9LFgwI+IO3sds33U9hUR8antKyQd6/EeR1r/HrP9sqT1kroGfADAcCRN6bwq6cHW4wclvTK/ge1ltpe3H0v6lqT9CfsFACxS0oD/z5Lusv0/ku5qPZftK21PttqslPRz2x9I+oWk1yJiZ8J+0QPlZgH0kmgdfkSckPTNLq8fkbSx9XhK0o1J+sFgKDcLoJ9S1dKpOsrNAuiHgF8ied7ZCED2CPgl0i4324lyswDaCPglQrlZAP2UrlpmleV1ZyMA+UDALxnKzQLohZQOAFQEAR8AKoKADwAVQcAHgIog4ANARbBKB8hYsxk6fOK0jp6c1cpLWEqL4SHgAxmi4B1GiZQOkKGyFLyjLHcxMMMHMtSv4F1Rbp7jLKU4mOEDGSpDwbuynKVUAQEfyFAZCt5Rlrs4SOkAGSpDwbv2WUpn0C/aWUpVMMMHMtYueHfL9St0/fjFhQr2UjnOUqqCGT6ARMpwlnKhinYPBQEfQGJVLMtdxNVJiVI6tu+3fcB203atT7sNtj+yfcj240n6BIA8KOLqpKQ5/P2S7pO0u1cD2xdJelrS3ZLWStpie23CfgEgU0VcnZQo4EfEwYj4aIFm6yUdioipiPhS0kuSNiXpFwCyVsR7KEaxSucqSZ90PJ9uvQYAhVXE1UkLXrS1/ZakVV0OPRERrwzQR7erFz0LbdjeKmmrJF1zzTUDvD0AjF4RVyctGPAj4s6EfUxLurrj+WpJR/r0t13Sdkmq1WpUYAKQW0VbnTSKlM57ktbYvs721yRtlvTqCPoFAHRIuizzXtvTkm6V9JrtXa3Xr7Q9KUkRcVbSI5J2STooaUdEHEg2bADAYiW68SoiXpb0cpfXj0ja2PF8UtJkkr4AAMlQSwcAKoKADwAVQcAHgIqgeBoKqWhVCoE8IOCjcIpYpRAYxLAnMqR0UDhFrFIILKQ9kdm4bY+2PPuuNm7bo50HPlOzmd79pwR8FE4RqxQCCxnFRIaAj8IpYpVCYCGjmMgQ8FE4RaxS2E2zGZpqzOjtj49rqjGT6qk7imcUExku2qJwililcD4uPGO+9kRm/u9EmhMZR+R3VlGr1aJer2c9DCB1U40Zbdy257xT+KVLxjT56O2FqbyI9LVX6SSZyNjeGxFdt5xlhg9koF++loBfXcMut0zAzwg3DlVbO187f4bPhWcMExdtMzCK9bbIt7JceEaxkMPPAPlbSOnka4H5yOHnDPlbSMXbHg/FR8DPQNHyt1xvAMqBHH4GipS/5XoDUB7k8DNSlPwt1xuAYiGHn0NFyd9yvQEoD1I66ItCZUB5EPDRV5GuNwDoL1FKx/b9kv5J0tclrY+Irgl324clnZL0W0lne+WXkD9lKFQGYE7SHP5+SfdJ+tEAbb8REccT9ocMFOV6A4D+EgX8iDgoSTazvbJgzT1QXqNapROS3rAdkn4UEdt7NbS9VdJWSbrmmmtGNDxI1GgHym7Bi7a237K9v8vPpkX0c1tE3CzpbkkP2/7jXg0jYntE1CKiNj4+vogukBSbgwPltuAMPyLuTNpJRBxp/XvM9suS1kvanfR9kS7W3APlNvRlmbaX2V7efizpW5q72IucYc09UG6JAr7te21PS7pV0mu2d7Vev9L2ZKvZSkk/t/2BpF9Iei0idibpF8PBmnug3Kilg/MUpcYPgO6opYOBseYeKC9KKwBARRDwAaAiCPgAUBEEfACoCAI+AFQEAR8AKoJlmR2oFAmgzAj4LVSKBFB2pHRaqBQJoOwI+C39KkUCQBkQ8FuoFAmg7Aj4LVSKBFB2XLRtGRuzNqxbpRsevZ1KkQBKiYDfgUqRAMqMlA4AVAQBHwAqgoAPABVBwAeAiiDgA0BF5HoTc9sNSb/KehwDWCHpeNaDyDk+o/74fPrj81lY+zO6NiLGuzXIdcAvCtv1XrvEYw6fUX98Pv3x+SxskM+IlA4AVAQBHwAqgoCfju1ZD6AA+Iz64/Ppj89nYQt+RuTwAaAimOEDQEUQ8AGgIgj4KbH9L7Z/aftD2y/bvjTrMeWJ7fttH7DdtM3yuhbbG2x/ZPuQ7cezHk/e2H7O9jHb+7MeSx7Zvtr2f9o+2Pp+/W2/9gT89Lwp6fcj4g8k/bekf8x4PHmzX9J9knZnPZC8sH2RpKcl3S1praQtttdmO6rceV7ShqwHkWNnJf19RHxd0i2SHu73O0TAT0lEvBERZ1tP35G0Osvx5E1EHIyIj7IeR86sl3QoIqYi4ktJL0nalPGYciUidkv6POtx5FVEfBoR77cen5J0UNJVvdoT8IfjLyW9nvUgkHtXSfqk4/m0+nxZgX5sT0j6Q0nv9mrDjleLYPstSau6HHoiIl5ptXlCc6dZPxnl2PJgkM8H5+m2fybrpLFoti+W9O+S/i4iTvZqR8BfhIi4s99x2w9KukfSN6OCNzgs9PngK6YlXd3xfLWkIxmNBQVle4nmgv1PIuI/+rUlpZMS2xsk/YOkP42I32Q9HhTCe5LW2L7O9tckbZb0asZjQoHYtqR/lXQwIp5cqD0BPz1PSVou6U3b+2w/k/WA8sT2vbanJd0q6TXbu7IeU9ZaF/kfkbRLcxfbdkTEgWxHlS+2X5T0tqTfsz1t+6+yHlPO3CbpzyT9SSvu7LO9sVdjSisAQEUwwweAiiDgA0BFEPABoCII+ABQEQR8AKgIAj4AVAQBHwAq4v8B7CFys2xA8vsAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# generate random data\n",
    "cor = .3\n",
    "alpha = cor**2\n",
    "n = 30\n",
    "x = np.random.randn(n)\n",
    "y = np.sqrt(1-alpha) * np.random.randn(n) + np.sqrt(alpha) * np.sign(cor) * x\n",
    "sns.scatterplot(x, y)\n",
    "\n",
    "# estimate of beta is different every time \n",
    "X = sm.add_constant(x)\n",
    "model = sm.OLS(y, X).fit()\n",
    "model.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the uncertainty in the estimate of beta\n",
    "m = 100\n",
    "params = np.zeros((m, 2))\n",
    "for trial in range(m):\n",
    "    cor = .3\n",
    "    alpha = cor**2\n",
    "    n = 30\n",
    "    x = np.random.randn(n)\n",
    "    y = np.sqrt(1-alpha) * np.random.randn(n) + np.sqrt(alpha) * np.sign(cor) * x\n",
    "\n",
    "    # estimate of beta is different every time \n",
    "    X = sm.add_constant(x)\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    params[trial, :] = model.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Count'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the uncertainty in the estimate of beta\n",
    "sns.histplot(params[:, 1], kde=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# how to estimate uncertainty in the estimate of beta in practice?\n",
    "\n",
    "* use a bootstrap to estimate the uncertainty in the estimate of beta\n",
    "* use the normal model to derive a formula for the uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.099</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.067</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   3.068</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 15 Mar 2023</td> <th>  Prob (F-statistic):</th>  <td>0.0908</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>12:34:42</td>     <th>  Log-Likelihood:    </th> <td> -35.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    30</td>      <th>  AIC:               </th> <td>   74.07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    28</td>      <th>  BIC:               </th> <td>   76.88</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   -0.2130</td> <td>    0.157</td> <td>   -1.354</td> <td> 0.187</td> <td>   -0.535</td> <td>    0.109</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.2306</td> <td>    0.132</td> <td>    1.752</td> <td> 0.091</td> <td>   -0.039</td> <td>    0.500</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 3.319</td> <th>  Durbin-Watson:     </th> <td>   1.887</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.190</td> <th>  Jarque-Bera (JB):  </th> <td>   1.490</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.114</td> <th>  Prob(JB):          </th> <td>   0.475</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 1.932</td> <th>  Cond. No.          </th> <td>    1.51</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.099\n",
       "Model:                            OLS   Adj. R-squared:                  0.067\n",
       "Method:                 Least Squares   F-statistic:                     3.068\n",
       "Date:                Wed, 15 Mar 2023   Prob (F-statistic):             0.0908\n",
       "Time:                        12:34:42   Log-Likelihood:                -35.037\n",
       "No. Observations:                  30   AIC:                             74.07\n",
       "Df Residuals:                      28   BIC:                             76.88\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         -0.2130      0.157     -1.354      0.187      -0.535       0.109\n",
       "x1             0.2306      0.132      1.752      0.091      -0.039       0.500\n",
       "==============================================================================\n",
       "Omnibus:                        3.319   Durbin-Watson:                   1.887\n",
       "Prob(Omnibus):                  0.190   Jarque-Bera (JB):                1.490\n",
       "Skew:                           0.114   Prob(JB):                        0.475\n",
       "Kurtosis:                       1.932   Cond. No.                         1.51\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model summary uses the normal model to compute std err, and associated confidence interval and p value\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What do p-values mean?\n",
    "\n",
    "* p-value is uniform [0,1] if feature x is uncorrelated with outcome y\n",
    "* p-value is smaller if feature x is correlated with outcome y\n",
    "\n",
    "try changing the correlation parameter in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7707424 , 0.07899949])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the correlation between x and y\n",
    "cor = 0\n",
    "\n",
    "# visualize the uncertainty in the estimate of beta\n",
    "m = 1000\n",
    "pvalues = np.zeros((m, 2))\n",
    "for trial in range(m):\n",
    "    alpha = cor**2\n",
    "    n = 30\n",
    "    x = np.random.randn(n)\n",
    "    y = np.sqrt(1-alpha) * np.random.randn(n) + np.sqrt(alpha) * np.sign(cor) * x\n",
    "\n",
    "    # estimate of beta is different every time \n",
    "    X = sm.add_constant(x)\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    pvalues[trial, :] = model.pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Count'>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(pvalues[:,1], bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.055, 0.056])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# around 5% of the pvalues are <.05, just by random chance \n",
    "sum(np.array(pvalues) <= .05) / len(pvalues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection and p values: be careful!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>...</th>\n",
       "      <th>x90</th>\n",
       "      <th>x91</th>\n",
       "      <th>x92</th>\n",
       "      <th>x93</th>\n",
       "      <th>x94</th>\n",
       "      <th>x95</th>\n",
       "      <th>x96</th>\n",
       "      <th>x97</th>\n",
       "      <th>x98</th>\n",
       "      <th>x99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.623254</td>\n",
       "      <td>-0.802040</td>\n",
       "      <td>0.054528</td>\n",
       "      <td>0.573241</td>\n",
       "      <td>-0.710244</td>\n",
       "      <td>0.263384</td>\n",
       "      <td>0.463138</td>\n",
       "      <td>0.115483</td>\n",
       "      <td>1.025473</td>\n",
       "      <td>0.101865</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.255342</td>\n",
       "      <td>-1.394777</td>\n",
       "      <td>0.328260</td>\n",
       "      <td>0.810497</td>\n",
       "      <td>-0.899081</td>\n",
       "      <td>-0.081717</td>\n",
       "      <td>2.535730</td>\n",
       "      <td>0.141986</td>\n",
       "      <td>1.472458</td>\n",
       "      <td>-1.118727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.239898</td>\n",
       "      <td>0.918592</td>\n",
       "      <td>1.607867</td>\n",
       "      <td>0.316869</td>\n",
       "      <td>1.874751</td>\n",
       "      <td>0.843463</td>\n",
       "      <td>-0.878260</td>\n",
       "      <td>0.068491</td>\n",
       "      <td>-0.365059</td>\n",
       "      <td>0.492198</td>\n",
       "      <td>...</td>\n",
       "      <td>1.481027</td>\n",
       "      <td>-1.323337</td>\n",
       "      <td>-0.158361</td>\n",
       "      <td>-0.822766</td>\n",
       "      <td>0.885847</td>\n",
       "      <td>-0.532316</td>\n",
       "      <td>0.463486</td>\n",
       "      <td>-0.069008</td>\n",
       "      <td>-0.625216</td>\n",
       "      <td>-1.073474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.542683</td>\n",
       "      <td>0.039553</td>\n",
       "      <td>1.184619</td>\n",
       "      <td>-0.178273</td>\n",
       "      <td>-1.081759</td>\n",
       "      <td>0.507279</td>\n",
       "      <td>-0.084141</td>\n",
       "      <td>-0.379923</td>\n",
       "      <td>0.552498</td>\n",
       "      <td>-0.243260</td>\n",
       "      <td>...</td>\n",
       "      <td>0.289320</td>\n",
       "      <td>-1.063214</td>\n",
       "      <td>-0.554801</td>\n",
       "      <td>-0.781533</td>\n",
       "      <td>0.638503</td>\n",
       "      <td>-0.673263</td>\n",
       "      <td>-0.599241</td>\n",
       "      <td>-0.640939</td>\n",
       "      <td>-1.222104</td>\n",
       "      <td>-1.537310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.094054</td>\n",
       "      <td>1.381927</td>\n",
       "      <td>0.153574</td>\n",
       "      <td>1.023250</td>\n",
       "      <td>0.045597</td>\n",
       "      <td>0.103349</td>\n",
       "      <td>-0.032535</td>\n",
       "      <td>0.506236</td>\n",
       "      <td>-1.114935</td>\n",
       "      <td>0.029036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.812528</td>\n",
       "      <td>-0.664168</td>\n",
       "      <td>0.420198</td>\n",
       "      <td>0.433262</td>\n",
       "      <td>-1.624309</td>\n",
       "      <td>0.285201</td>\n",
       "      <td>0.451823</td>\n",
       "      <td>1.204218</td>\n",
       "      <td>-0.014775</td>\n",
       "      <td>-2.143995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.887388</td>\n",
       "      <td>0.809840</td>\n",
       "      <td>0.236358</td>\n",
       "      <td>1.134181</td>\n",
       "      <td>-0.310011</td>\n",
       "      <td>-1.310849</td>\n",
       "      <td>0.758173</td>\n",
       "      <td>2.401749</td>\n",
       "      <td>-0.895524</td>\n",
       "      <td>-0.564146</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.689074</td>\n",
       "      <td>-0.210007</td>\n",
       "      <td>0.108338</td>\n",
       "      <td>0.867975</td>\n",
       "      <td>1.146043</td>\n",
       "      <td>0.665636</td>\n",
       "      <td>-1.200726</td>\n",
       "      <td>1.710236</td>\n",
       "      <td>-1.253896</td>\n",
       "      <td>-0.001382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         x0        x1        x2        x3        x4        x5        x6  \\\n",
       "0  2.623254 -0.802040  0.054528  0.573241 -0.710244  0.263384  0.463138   \n",
       "1 -1.239898  0.918592  1.607867  0.316869  1.874751  0.843463 -0.878260   \n",
       "2  0.542683  0.039553  1.184619 -0.178273 -1.081759  0.507279 -0.084141   \n",
       "3 -0.094054  1.381927  0.153574  1.023250  0.045597  0.103349 -0.032535   \n",
       "4 -0.887388  0.809840  0.236358  1.134181 -0.310011 -1.310849  0.758173   \n",
       "\n",
       "         x7        x8        x9  ...       x90       x91       x92       x93  \\\n",
       "0  0.115483  1.025473  0.101865  ... -0.255342 -1.394777  0.328260  0.810497   \n",
       "1  0.068491 -0.365059  0.492198  ...  1.481027 -1.323337 -0.158361 -0.822766   \n",
       "2 -0.379923  0.552498 -0.243260  ...  0.289320 -1.063214 -0.554801 -0.781533   \n",
       "3  0.506236 -1.114935  0.029036  ...  0.812528 -0.664168  0.420198  0.433262   \n",
       "4  2.401749 -0.895524 -0.564146  ... -1.689074 -0.210007  0.108338  0.867975   \n",
       "\n",
       "        x94       x95       x96       x97       x98       x99  \n",
       "0 -0.899081 -0.081717  2.535730  0.141986  1.472458 -1.118727  \n",
       "1  0.885847 -0.532316  0.463486 -0.069008 -0.625216 -1.073474  \n",
       "2  0.638503 -0.673263 -0.599241 -0.640939 -1.222104 -1.537310  \n",
       "3 -1.624309  0.285201  0.451823  1.204218 -0.014775 -2.143995  \n",
       "4  1.146043  0.665636 -1.200726  1.710236 -1.253896 -0.001382  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "n = 500\n",
    "p = 100\n",
    "for j in range(p):\n",
    "    xp = 'x'+str(j)\n",
    "    df[xp] = np.random.randn(n)\n",
    "y = np.random.randn(n)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared (uncentered):</th>      <td>   0.247</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.059</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   1.314</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 13 Mar 2023</td> <th>  Prob (F-statistic):</th>           <td>0.0358</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:50:03</td>     <th>  Log-Likelihood:    </th>          <td> -657.03</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   500</td>      <th>  AIC:               </th>          <td>   1514.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   400</td>      <th>  BIC:               </th>          <td>   1936.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>   100</td>      <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "   <td></td>      <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x0</th>  <td>    0.0370</td> <td>    0.048</td> <td>    0.772</td> <td> 0.441</td> <td>   -0.057</td> <td>    0.131</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>  <td>   -0.0050</td> <td>    0.046</td> <td>   -0.109</td> <td> 0.913</td> <td>   -0.095</td> <td>    0.085</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>  <td>    0.0580</td> <td>    0.048</td> <td>    1.210</td> <td> 0.227</td> <td>   -0.036</td> <td>    0.152</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>  <td>   -0.0524</td> <td>    0.051</td> <td>   -1.021</td> <td> 0.308</td> <td>   -0.153</td> <td>    0.049</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>  <td>   -0.0281</td> <td>    0.049</td> <td>   -0.575</td> <td> 0.565</td> <td>   -0.124</td> <td>    0.068</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>  <td>   -0.0510</td> <td>    0.051</td> <td>   -0.998</td> <td> 0.319</td> <td>   -0.151</td> <td>    0.049</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>  <td>    0.0118</td> <td>    0.048</td> <td>    0.247</td> <td> 0.805</td> <td>   -0.082</td> <td>    0.106</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>  <td>    0.1151</td> <td>    0.053</td> <td>    2.159</td> <td> 0.031</td> <td>    0.010</td> <td>    0.220</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>  <td>    0.0896</td> <td>    0.049</td> <td>    1.842</td> <td> 0.066</td> <td>   -0.006</td> <td>    0.185</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>  <td>    0.0055</td> <td>    0.052</td> <td>    0.108</td> <td> 0.914</td> <td>   -0.096</td> <td>    0.107</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th> <td>    0.0225</td> <td>    0.051</td> <td>    0.442</td> <td> 0.658</td> <td>   -0.077</td> <td>    0.122</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th> <td>   -0.0968</td> <td>    0.051</td> <td>   -1.889</td> <td> 0.060</td> <td>   -0.198</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th> <td>    0.0328</td> <td>    0.051</td> <td>    0.646</td> <td> 0.519</td> <td>   -0.067</td> <td>    0.133</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th> <td>   -0.0364</td> <td>    0.053</td> <td>   -0.687</td> <td> 0.493</td> <td>   -0.141</td> <td>    0.068</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th> <td>   -0.0349</td> <td>    0.049</td> <td>   -0.709</td> <td> 0.479</td> <td>   -0.132</td> <td>    0.062</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th> <td>    0.0124</td> <td>    0.053</td> <td>    0.236</td> <td> 0.814</td> <td>   -0.091</td> <td>    0.116</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th> <td>   -0.0179</td> <td>    0.048</td> <td>   -0.371</td> <td> 0.711</td> <td>   -0.113</td> <td>    0.077</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th> <td>   -0.0707</td> <td>    0.051</td> <td>   -1.395</td> <td> 0.164</td> <td>   -0.170</td> <td>    0.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th> <td>    0.0314</td> <td>    0.051</td> <td>    0.615</td> <td> 0.539</td> <td>   -0.069</td> <td>    0.132</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th> <td>    0.0646</td> <td>    0.050</td> <td>    1.294</td> <td> 0.197</td> <td>   -0.034</td> <td>    0.163</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20</th> <td>    0.0120</td> <td>    0.051</td> <td>    0.236</td> <td> 0.814</td> <td>   -0.088</td> <td>    0.112</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21</th> <td>    0.0360</td> <td>    0.051</td> <td>    0.704</td> <td> 0.482</td> <td>   -0.064</td> <td>    0.136</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22</th> <td>   -0.0141</td> <td>    0.050</td> <td>   -0.280</td> <td> 0.780</td> <td>   -0.113</td> <td>    0.085</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23</th> <td>   -0.0211</td> <td>    0.052</td> <td>   -0.405</td> <td> 0.686</td> <td>   -0.124</td> <td>    0.081</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24</th> <td>   -0.0580</td> <td>    0.047</td> <td>   -1.232</td> <td> 0.219</td> <td>   -0.151</td> <td>    0.035</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25</th> <td>   -0.0819</td> <td>    0.051</td> <td>   -1.611</td> <td> 0.108</td> <td>   -0.182</td> <td>    0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x26</th> <td>   -0.0464</td> <td>    0.050</td> <td>   -0.919</td> <td> 0.359</td> <td>   -0.146</td> <td>    0.053</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x27</th> <td>   -0.0404</td> <td>    0.047</td> <td>   -0.857</td> <td> 0.392</td> <td>   -0.133</td> <td>    0.052</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x28</th> <td>   -0.1400</td> <td>    0.048</td> <td>   -2.905</td> <td> 0.004</td> <td>   -0.235</td> <td>   -0.045</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x29</th> <td>    0.0075</td> <td>    0.049</td> <td>    0.152</td> <td> 0.879</td> <td>   -0.089</td> <td>    0.104</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x30</th> <td>   -0.0691</td> <td>    0.050</td> <td>   -1.374</td> <td> 0.170</td> <td>   -0.168</td> <td>    0.030</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x31</th> <td>   -0.0377</td> <td>    0.050</td> <td>   -0.761</td> <td> 0.447</td> <td>   -0.135</td> <td>    0.060</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x32</th> <td>   -0.0472</td> <td>    0.050</td> <td>   -0.950</td> <td> 0.343</td> <td>   -0.145</td> <td>    0.050</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x33</th> <td>   -0.0776</td> <td>    0.053</td> <td>   -1.451</td> <td> 0.148</td> <td>   -0.183</td> <td>    0.028</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x34</th> <td>    0.0392</td> <td>    0.050</td> <td>    0.786</td> <td> 0.432</td> <td>   -0.059</td> <td>    0.137</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x35</th> <td>    0.0032</td> <td>    0.050</td> <td>    0.063</td> <td> 0.950</td> <td>   -0.095</td> <td>    0.102</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x36</th> <td>   -0.0625</td> <td>    0.049</td> <td>   -1.285</td> <td> 0.200</td> <td>   -0.158</td> <td>    0.033</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x37</th> <td>   -0.0177</td> <td>    0.052</td> <td>   -0.339</td> <td> 0.735</td> <td>   -0.120</td> <td>    0.085</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x38</th> <td>   -0.0169</td> <td>    0.051</td> <td>   -0.334</td> <td> 0.738</td> <td>   -0.117</td> <td>    0.083</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x39</th> <td>   -0.0222</td> <td>    0.051</td> <td>   -0.432</td> <td> 0.666</td> <td>   -0.123</td> <td>    0.079</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x40</th> <td>   -0.0502</td> <td>    0.051</td> <td>   -0.993</td> <td> 0.321</td> <td>   -0.150</td> <td>    0.049</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x41</th> <td>    0.1218</td> <td>    0.052</td> <td>    2.321</td> <td> 0.021</td> <td>    0.019</td> <td>    0.225</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x42</th> <td>    0.0048</td> <td>    0.050</td> <td>    0.096</td> <td> 0.924</td> <td>   -0.094</td> <td>    0.103</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x43</th> <td>    0.0180</td> <td>    0.050</td> <td>    0.364</td> <td> 0.716</td> <td>   -0.079</td> <td>    0.115</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x44</th> <td>    0.0923</td> <td>    0.053</td> <td>    1.729</td> <td> 0.085</td> <td>   -0.013</td> <td>    0.197</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x45</th> <td>    0.0703</td> <td>    0.051</td> <td>    1.384</td> <td> 0.167</td> <td>   -0.030</td> <td>    0.170</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x46</th> <td>   -0.0157</td> <td>    0.050</td> <td>   -0.311</td> <td> 0.756</td> <td>   -0.115</td> <td>    0.083</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x47</th> <td>    0.0458</td> <td>    0.053</td> <td>    0.868</td> <td> 0.386</td> <td>   -0.058</td> <td>    0.150</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x48</th> <td>    0.0660</td> <td>    0.051</td> <td>    1.300</td> <td> 0.194</td> <td>   -0.034</td> <td>    0.166</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x49</th> <td>    0.0198</td> <td>    0.053</td> <td>    0.375</td> <td> 0.708</td> <td>   -0.084</td> <td>    0.124</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x50</th> <td>   -0.0299</td> <td>    0.047</td> <td>   -0.632</td> <td> 0.528</td> <td>   -0.123</td> <td>    0.063</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x51</th> <td>    0.0531</td> <td>    0.047</td> <td>    1.125</td> <td> 0.261</td> <td>   -0.040</td> <td>    0.146</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x52</th> <td>    0.0993</td> <td>    0.049</td> <td>    2.024</td> <td> 0.044</td> <td>    0.003</td> <td>    0.196</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x53</th> <td>    0.0643</td> <td>    0.050</td> <td>    1.294</td> <td> 0.196</td> <td>   -0.033</td> <td>    0.162</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x54</th> <td>   -0.0798</td> <td>    0.051</td> <td>   -1.563</td> <td> 0.119</td> <td>   -0.180</td> <td>    0.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x55</th> <td>    0.0270</td> <td>    0.051</td> <td>    0.525</td> <td> 0.600</td> <td>   -0.074</td> <td>    0.128</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x56</th> <td>    0.0059</td> <td>    0.054</td> <td>    0.109</td> <td> 0.913</td> <td>   -0.100</td> <td>    0.112</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x57</th> <td>   -0.0472</td> <td>    0.050</td> <td>   -0.949</td> <td> 0.343</td> <td>   -0.145</td> <td>    0.051</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x58</th> <td>    0.0217</td> <td>    0.049</td> <td>    0.439</td> <td> 0.661</td> <td>   -0.075</td> <td>    0.119</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x59</th> <td>    0.0721</td> <td>    0.050</td> <td>    1.455</td> <td> 0.146</td> <td>   -0.025</td> <td>    0.170</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x60</th> <td>    0.0645</td> <td>    0.046</td> <td>    1.392</td> <td> 0.165</td> <td>   -0.027</td> <td>    0.156</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x61</th> <td>    0.0214</td> <td>    0.051</td> <td>    0.420</td> <td> 0.674</td> <td>   -0.079</td> <td>    0.121</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x62</th> <td>   -0.1116</td> <td>    0.051</td> <td>   -2.207</td> <td> 0.028</td> <td>   -0.211</td> <td>   -0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x63</th> <td>    0.0153</td> <td>    0.050</td> <td>    0.307</td> <td> 0.759</td> <td>   -0.083</td> <td>    0.114</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x64</th> <td>    0.0104</td> <td>    0.051</td> <td>    0.205</td> <td> 0.838</td> <td>   -0.089</td> <td>    0.110</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x65</th> <td>   -0.0207</td> <td>    0.052</td> <td>   -0.400</td> <td> 0.689</td> <td>   -0.122</td> <td>    0.081</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x66</th> <td>   -0.0363</td> <td>    0.049</td> <td>   -0.747</td> <td> 0.455</td> <td>   -0.132</td> <td>    0.059</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x67</th> <td>    0.1421</td> <td>    0.054</td> <td>    2.614</td> <td> 0.009</td> <td>    0.035</td> <td>    0.249</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x68</th> <td>   -0.0328</td> <td>    0.049</td> <td>   -0.667</td> <td> 0.505</td> <td>   -0.129</td> <td>    0.064</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x69</th> <td>   -0.0325</td> <td>    0.051</td> <td>   -0.636</td> <td> 0.525</td> <td>   -0.133</td> <td>    0.068</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x70</th> <td>   -0.0124</td> <td>    0.050</td> <td>   -0.246</td> <td> 0.806</td> <td>   -0.112</td> <td>    0.087</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x71</th> <td>   -0.0718</td> <td>    0.053</td> <td>   -1.360</td> <td> 0.175</td> <td>   -0.176</td> <td>    0.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x72</th> <td>   -0.0094</td> <td>    0.052</td> <td>   -0.179</td> <td> 0.858</td> <td>   -0.112</td> <td>    0.094</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x73</th> <td>    0.0419</td> <td>    0.052</td> <td>    0.805</td> <td> 0.421</td> <td>   -0.060</td> <td>    0.144</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x74</th> <td>   -0.0447</td> <td>    0.048</td> <td>   -0.929</td> <td> 0.353</td> <td>   -0.139</td> <td>    0.050</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x75</th> <td>   -0.0003</td> <td>    0.049</td> <td>   -0.007</td> <td> 0.994</td> <td>   -0.096</td> <td>    0.096</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x76</th> <td>    0.0587</td> <td>    0.050</td> <td>    1.181</td> <td> 0.238</td> <td>   -0.039</td> <td>    0.157</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x77</th> <td>   -0.0352</td> <td>    0.052</td> <td>   -0.680</td> <td> 0.497</td> <td>   -0.137</td> <td>    0.067</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x78</th> <td>   -0.0683</td> <td>    0.051</td> <td>   -1.331</td> <td> 0.184</td> <td>   -0.169</td> <td>    0.033</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x79</th> <td>    0.0478</td> <td>    0.050</td> <td>    0.957</td> <td> 0.339</td> <td>   -0.050</td> <td>    0.146</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x80</th> <td>   -0.0718</td> <td>    0.050</td> <td>   -1.434</td> <td> 0.152</td> <td>   -0.170</td> <td>    0.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x81</th> <td>   -0.0874</td> <td>    0.050</td> <td>   -1.739</td> <td> 0.083</td> <td>   -0.186</td> <td>    0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x82</th> <td>   -0.0440</td> <td>    0.051</td> <td>   -0.869</td> <td> 0.385</td> <td>   -0.143</td> <td>    0.055</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x83</th> <td>   -0.1148</td> <td>    0.050</td> <td>   -2.285</td> <td> 0.023</td> <td>   -0.213</td> <td>   -0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x84</th> <td>   -0.0934</td> <td>    0.050</td> <td>   -1.854</td> <td> 0.065</td> <td>   -0.193</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x85</th> <td>   -0.0201</td> <td>    0.050</td> <td>   -0.400</td> <td> 0.690</td> <td>   -0.119</td> <td>    0.079</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x86</th> <td>    0.0702</td> <td>    0.049</td> <td>    1.438</td> <td> 0.151</td> <td>   -0.026</td> <td>    0.166</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x87</th> <td>    0.0039</td> <td>    0.051</td> <td>    0.077</td> <td> 0.939</td> <td>   -0.097</td> <td>    0.105</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x88</th> <td>    0.0920</td> <td>    0.048</td> <td>    1.900</td> <td> 0.058</td> <td>   -0.003</td> <td>    0.187</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x89</th> <td>   -0.0158</td> <td>    0.051</td> <td>   -0.309</td> <td> 0.757</td> <td>   -0.116</td> <td>    0.085</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x90</th> <td>   -0.0823</td> <td>    0.049</td> <td>   -1.663</td> <td> 0.097</td> <td>   -0.180</td> <td>    0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x91</th> <td>   -0.0845</td> <td>    0.048</td> <td>   -1.743</td> <td> 0.082</td> <td>   -0.180</td> <td>    0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x92</th> <td>    0.0007</td> <td>    0.048</td> <td>    0.014</td> <td> 0.989</td> <td>   -0.093</td> <td>    0.095</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x93</th> <td>    0.0575</td> <td>    0.052</td> <td>    1.109</td> <td> 0.268</td> <td>   -0.044</td> <td>    0.159</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x94</th> <td>    0.0684</td> <td>    0.052</td> <td>    1.321</td> <td> 0.187</td> <td>   -0.033</td> <td>    0.170</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x95</th> <td>    0.0906</td> <td>    0.050</td> <td>    1.831</td> <td> 0.068</td> <td>   -0.007</td> <td>    0.188</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x96</th> <td>   -0.0461</td> <td>    0.050</td> <td>   -0.920</td> <td> 0.358</td> <td>   -0.145</td> <td>    0.052</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x97</th> <td>   -0.0159</td> <td>    0.048</td> <td>   -0.332</td> <td> 0.740</td> <td>   -0.110</td> <td>    0.078</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x98</th> <td>    0.0333</td> <td>    0.052</td> <td>    0.646</td> <td> 0.519</td> <td>   -0.068</td> <td>    0.135</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x99</th> <td>   -0.0340</td> <td>    0.049</td> <td>   -0.688</td> <td> 0.492</td> <td>   -0.131</td> <td>    0.063</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.201</td> <th>  Durbin-Watson:     </th> <td>   2.092</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.905</td> <th>  Jarque-Bera (JB):  </th> <td>   0.149</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.042</td> <th>  Prob(JB):          </th> <td>   0.928</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.015</td> <th>  Cond. No.          </th> <td>    2.49</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] R² is computed without centering (uncentered) since the model does not contain a constant.<br/>[2] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:                      y   R-squared (uncentered):                   0.247\n",
       "Model:                            OLS   Adj. R-squared (uncentered):              0.059\n",
       "Method:                 Least Squares   F-statistic:                              1.314\n",
       "Date:                Mon, 13 Mar 2023   Prob (F-statistic):                      0.0358\n",
       "Time:                        11:50:03   Log-Likelihood:                         -657.03\n",
       "No. Observations:                 500   AIC:                                      1514.\n",
       "Df Residuals:                     400   BIC:                                      1936.\n",
       "Df Model:                         100                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "x0             0.0370      0.048      0.772      0.441      -0.057       0.131\n",
       "x1            -0.0050      0.046     -0.109      0.913      -0.095       0.085\n",
       "x2             0.0580      0.048      1.210      0.227      -0.036       0.152\n",
       "x3            -0.0524      0.051     -1.021      0.308      -0.153       0.049\n",
       "x4            -0.0281      0.049     -0.575      0.565      -0.124       0.068\n",
       "x5            -0.0510      0.051     -0.998      0.319      -0.151       0.049\n",
       "x6             0.0118      0.048      0.247      0.805      -0.082       0.106\n",
       "x7             0.1151      0.053      2.159      0.031       0.010       0.220\n",
       "x8             0.0896      0.049      1.842      0.066      -0.006       0.185\n",
       "x9             0.0055      0.052      0.108      0.914      -0.096       0.107\n",
       "x10            0.0225      0.051      0.442      0.658      -0.077       0.122\n",
       "x11           -0.0968      0.051     -1.889      0.060      -0.198       0.004\n",
       "x12            0.0328      0.051      0.646      0.519      -0.067       0.133\n",
       "x13           -0.0364      0.053     -0.687      0.493      -0.141       0.068\n",
       "x14           -0.0349      0.049     -0.709      0.479      -0.132       0.062\n",
       "x15            0.0124      0.053      0.236      0.814      -0.091       0.116\n",
       "x16           -0.0179      0.048     -0.371      0.711      -0.113       0.077\n",
       "x17           -0.0707      0.051     -1.395      0.164      -0.170       0.029\n",
       "x18            0.0314      0.051      0.615      0.539      -0.069       0.132\n",
       "x19            0.0646      0.050      1.294      0.197      -0.034       0.163\n",
       "x20            0.0120      0.051      0.236      0.814      -0.088       0.112\n",
       "x21            0.0360      0.051      0.704      0.482      -0.064       0.136\n",
       "x22           -0.0141      0.050     -0.280      0.780      -0.113       0.085\n",
       "x23           -0.0211      0.052     -0.405      0.686      -0.124       0.081\n",
       "x24           -0.0580      0.047     -1.232      0.219      -0.151       0.035\n",
       "x25           -0.0819      0.051     -1.611      0.108      -0.182       0.018\n",
       "x26           -0.0464      0.050     -0.919      0.359      -0.146       0.053\n",
       "x27           -0.0404      0.047     -0.857      0.392      -0.133       0.052\n",
       "x28           -0.1400      0.048     -2.905      0.004      -0.235      -0.045\n",
       "x29            0.0075      0.049      0.152      0.879      -0.089       0.104\n",
       "x30           -0.0691      0.050     -1.374      0.170      -0.168       0.030\n",
       "x31           -0.0377      0.050     -0.761      0.447      -0.135       0.060\n",
       "x32           -0.0472      0.050     -0.950      0.343      -0.145       0.050\n",
       "x33           -0.0776      0.053     -1.451      0.148      -0.183       0.028\n",
       "x34            0.0392      0.050      0.786      0.432      -0.059       0.137\n",
       "x35            0.0032      0.050      0.063      0.950      -0.095       0.102\n",
       "x36           -0.0625      0.049     -1.285      0.200      -0.158       0.033\n",
       "x37           -0.0177      0.052     -0.339      0.735      -0.120       0.085\n",
       "x38           -0.0169      0.051     -0.334      0.738      -0.117       0.083\n",
       "x39           -0.0222      0.051     -0.432      0.666      -0.123       0.079\n",
       "x40           -0.0502      0.051     -0.993      0.321      -0.150       0.049\n",
       "x41            0.1218      0.052      2.321      0.021       0.019       0.225\n",
       "x42            0.0048      0.050      0.096      0.924      -0.094       0.103\n",
       "x43            0.0180      0.050      0.364      0.716      -0.079       0.115\n",
       "x44            0.0923      0.053      1.729      0.085      -0.013       0.197\n",
       "x45            0.0703      0.051      1.384      0.167      -0.030       0.170\n",
       "x46           -0.0157      0.050     -0.311      0.756      -0.115       0.083\n",
       "x47            0.0458      0.053      0.868      0.386      -0.058       0.150\n",
       "x48            0.0660      0.051      1.300      0.194      -0.034       0.166\n",
       "x49            0.0198      0.053      0.375      0.708      -0.084       0.124\n",
       "x50           -0.0299      0.047     -0.632      0.528      -0.123       0.063\n",
       "x51            0.0531      0.047      1.125      0.261      -0.040       0.146\n",
       "x52            0.0993      0.049      2.024      0.044       0.003       0.196\n",
       "x53            0.0643      0.050      1.294      0.196      -0.033       0.162\n",
       "x54           -0.0798      0.051     -1.563      0.119      -0.180       0.021\n",
       "x55            0.0270      0.051      0.525      0.600      -0.074       0.128\n",
       "x56            0.0059      0.054      0.109      0.913      -0.100       0.112\n",
       "x57           -0.0472      0.050     -0.949      0.343      -0.145       0.051\n",
       "x58            0.0217      0.049      0.439      0.661      -0.075       0.119\n",
       "x59            0.0721      0.050      1.455      0.146      -0.025       0.170\n",
       "x60            0.0645      0.046      1.392      0.165      -0.027       0.156\n",
       "x61            0.0214      0.051      0.420      0.674      -0.079       0.121\n",
       "x62           -0.1116      0.051     -2.207      0.028      -0.211      -0.012\n",
       "x63            0.0153      0.050      0.307      0.759      -0.083       0.114\n",
       "x64            0.0104      0.051      0.205      0.838      -0.089       0.110\n",
       "x65           -0.0207      0.052     -0.400      0.689      -0.122       0.081\n",
       "x66           -0.0363      0.049     -0.747      0.455      -0.132       0.059\n",
       "x67            0.1421      0.054      2.614      0.009       0.035       0.249\n",
       "x68           -0.0328      0.049     -0.667      0.505      -0.129       0.064\n",
       "x69           -0.0325      0.051     -0.636      0.525      -0.133       0.068\n",
       "x70           -0.0124      0.050     -0.246      0.806      -0.112       0.087\n",
       "x71           -0.0718      0.053     -1.360      0.175      -0.176       0.032\n",
       "x72           -0.0094      0.052     -0.179      0.858      -0.112       0.094\n",
       "x73            0.0419      0.052      0.805      0.421      -0.060       0.144\n",
       "x74           -0.0447      0.048     -0.929      0.353      -0.139       0.050\n",
       "x75           -0.0003      0.049     -0.007      0.994      -0.096       0.096\n",
       "x76            0.0587      0.050      1.181      0.238      -0.039       0.157\n",
       "x77           -0.0352      0.052     -0.680      0.497      -0.137       0.067\n",
       "x78           -0.0683      0.051     -1.331      0.184      -0.169       0.033\n",
       "x79            0.0478      0.050      0.957      0.339      -0.050       0.146\n",
       "x80           -0.0718      0.050     -1.434      0.152      -0.170       0.027\n",
       "x81           -0.0874      0.050     -1.739      0.083      -0.186       0.011\n",
       "x82           -0.0440      0.051     -0.869      0.385      -0.143       0.055\n",
       "x83           -0.1148      0.050     -2.285      0.023      -0.213      -0.016\n",
       "x84           -0.0934      0.050     -1.854      0.065      -0.193       0.006\n",
       "x85           -0.0201      0.050     -0.400      0.690      -0.119       0.079\n",
       "x86            0.0702      0.049      1.438      0.151      -0.026       0.166\n",
       "x87            0.0039      0.051      0.077      0.939      -0.097       0.105\n",
       "x88            0.0920      0.048      1.900      0.058      -0.003       0.187\n",
       "x89           -0.0158      0.051     -0.309      0.757      -0.116       0.085\n",
       "x90           -0.0823      0.049     -1.663      0.097      -0.180       0.015\n",
       "x91           -0.0845      0.048     -1.743      0.082      -0.180       0.011\n",
       "x92            0.0007      0.048      0.014      0.989      -0.093       0.095\n",
       "x93            0.0575      0.052      1.109      0.268      -0.044       0.159\n",
       "x94            0.0684      0.052      1.321      0.187      -0.033       0.170\n",
       "x95            0.0906      0.050      1.831      0.068      -0.007       0.188\n",
       "x96           -0.0461      0.050     -0.920      0.358      -0.145       0.052\n",
       "x97           -0.0159      0.048     -0.332      0.740      -0.110       0.078\n",
       "x98            0.0333      0.052      0.646      0.519      -0.068       0.135\n",
       "x99           -0.0340      0.049     -0.688      0.492      -0.131       0.063\n",
       "==============================================================================\n",
       "Omnibus:                        0.201   Durbin-Watson:                   2.092\n",
       "Prob(Omnibus):                  0.905   Jarque-Bera (JB):                0.149\n",
       "Skew:                          -0.042   Prob(JB):                        0.928\n",
       "Kurtosis:                       3.015   Cond. No.                         2.49\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
       "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variables = df.columns\n",
    "model = sm.OLS(y,df[variables]).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared (uncentered):</th>      <td>   0.070</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.057</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   5.294</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 13 Mar 2023</td> <th>  Prob (F-statistic):</th>          <td>7.54e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:50:03</td>     <th>  Log-Likelihood:    </th>          <td> -709.91</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   500</td>      <th>  AIC:               </th>          <td>   1434.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   493</td>      <th>  BIC:               </th>          <td>   1463.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     7</td>      <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "   <td></td>      <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>  <td>    0.0784</td> <td>    0.047</td> <td>    1.656</td> <td> 0.098</td> <td>   -0.015</td> <td>    0.171</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x28</th> <td>   -0.1576</td> <td>    0.044</td> <td>   -3.591</td> <td> 0.000</td> <td>   -0.244</td> <td>   -0.071</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x41</th> <td>    0.1123</td> <td>    0.047</td> <td>    2.406</td> <td> 0.016</td> <td>    0.021</td> <td>    0.204</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x52</th> <td>    0.1051</td> <td>    0.045</td> <td>    2.317</td> <td> 0.021</td> <td>    0.016</td> <td>    0.194</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x62</th> <td>   -0.0843</td> <td>    0.046</td> <td>   -1.843</td> <td> 0.066</td> <td>   -0.174</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x67</th> <td>    0.1131</td> <td>    0.048</td> <td>    2.333</td> <td> 0.020</td> <td>    0.018</td> <td>    0.208</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x83</th> <td>   -0.0809</td> <td>    0.046</td> <td>   -1.767</td> <td> 0.078</td> <td>   -0.171</td> <td>    0.009</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.627</td> <th>  Durbin-Watson:     </th> <td>   1.965</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.731</td> <th>  Jarque-Bera (JB):  </th> <td>   0.481</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.064</td> <th>  Prob(JB):          </th> <td>   0.786</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.082</td> <th>  Cond. No.          </th> <td>    1.26</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] R² is computed without centering (uncentered) since the model does not contain a constant.<br/>[2] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:                      y   R-squared (uncentered):                   0.070\n",
       "Model:                            OLS   Adj. R-squared (uncentered):              0.057\n",
       "Method:                 Least Squares   F-statistic:                              5.294\n",
       "Date:                Mon, 13 Mar 2023   Prob (F-statistic):                    7.54e-06\n",
       "Time:                        11:50:03   Log-Likelihood:                         -709.91\n",
       "No. Observations:                 500   AIC:                                      1434.\n",
       "Df Residuals:                     493   BIC:                                      1463.\n",
       "Df Model:                           7                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "x7             0.0784      0.047      1.656      0.098      -0.015       0.171\n",
       "x28           -0.1576      0.044     -3.591      0.000      -0.244      -0.071\n",
       "x41            0.1123      0.047      2.406      0.016       0.021       0.204\n",
       "x52            0.1051      0.045      2.317      0.021       0.016       0.194\n",
       "x62           -0.0843      0.046     -1.843      0.066      -0.174       0.006\n",
       "x67            0.1131      0.048      2.333      0.020       0.018       0.208\n",
       "x83           -0.0809      0.046     -1.767      0.078      -0.171       0.009\n",
       "==============================================================================\n",
       "Omnibus:                        0.627   Durbin-Watson:                   1.965\n",
       "Prob(Omnibus):                  0.731   Jarque-Bera (JB):                0.481\n",
       "Skew:                          -0.064   Prob(JB):                        0.786\n",
       "Kurtosis:                       3.082   Cond. No.                         1.26\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
       "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# uncomment this line the first time you run the cell; comment it out for subsequent runs\n",
    "stat_sig_vars = variables\n",
    "stat_sig_vars = stat_sig_vars[model.pvalues <= .05]\n",
    "model = sm.OLS(y,df[stat_sig_vars]).fit()\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "2e8b7f62927fe0753cae67d9a5877941773e0f948637a4bc940202eeb3c19f2e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
